input {
  beats {
    port => 5044
  }
  
  file {
    path => ["/logs/development.log", "/logs/production.log"]
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => json
  }
}

filter {
  # Your logs are already in JSON format, so we can work with them directly
  
  # Parse the custom timestamp format from Winston (DD MMM YYYY HH:mm)
  if [timestamp] {
    date {
      match => [ "timestamp", "dd MMM yyyy HH:mm" ]
      timezone => "Asia/Kolkata"
      target => "@timestamp"
    }
  }
  
  # Add service information
  mutate {
    add_field => { "service" => "backend" }
    add_field => { "application" => "prod-server" }
  }
  
  # Determine log file source and environment
  if [path] =~ /development\.log$/ {
    mutate {
      add_field => { 
        "log_type" => "development" 
        "environment" => "development"
      }
    }
  } else if [path] =~ /production\.log$/ {
    mutate {
      add_field => { 
        "log_type" => "production"
        "environment" => "production"
      }
    }
  }
  
  # Handle error objects in meta field
  if [meta] {
    ruby {
      code => "
        meta = event.get('meta')
        if meta.is_a?(Hash)
          meta.each do |key, value|
            if value.is_a?(Hash) && value['name'] && value['message'] && value['trace']
              # This is an error object
              event.set('error_name', value['name'])
              event.set('error_message', value['message'])
              event.set('error_stack', value['trace'])
              event.set('has_error', true)
            end
          end
        end
      "
    }
  }
  
  # Add log parsing success indicator
  mutate {
    add_field => { "parsed_successfully" => "true" }
  }
  
  # Clean up unnecessary fields but keep important ones
  mutate {
    remove_field => [ "host", "agent", "ecs", "input" ]
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "backend-logs-%{+YYYY.MM.dd}"
  }
  
  # Debug output (optional)
  stdout {
    codec => rubydebug
  }
}